{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7EPnvkARAhJtYW/cZFhlZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubacca/pyspark-retail/blob/main/retail_exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install faker pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6X373cfssk4",
        "outputId": "d42d5f1c-d871-4303-f38c-4d43de29aa6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-26.2.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Downloading Faker-26.2.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=31e742df5f474472184e49b4610ec3c89aa1802989c10107541349d7119fb8f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark, faker\n",
            "Successfully installed faker-26.2.0 pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, BooleanType, DateType\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "0YLsShtEuF_W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"RetailDataset\").getOrCreate()"
      ],
      "metadata": {
        "id": "M_uuw5EZsusW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake = Faker()\n",
        "\n",
        "def generate_customers(n):\n",
        "    customers = []\n",
        "    for i in range(n):\n",
        "        customer = {\n",
        "            \"customer_id\": i,\n",
        "            \"first_name\": fake.first_name(),\n",
        "            \"last_name\": fake.last_name(),\n",
        "            \"email\": fake.email(),\n",
        "            \"is_active\": fake.boolean(),\n",
        "            \"is_loyalty_member\": fake.boolean()\n",
        "        }\n",
        "        customers.append(customer)\n",
        "    return customers\n",
        "\n",
        "def generate_products(n):\n",
        "    products = []\n",
        "    for i in range(n):\n",
        "        product = {\n",
        "            \"product_id\": i,\n",
        "            \"product_name\": fake.word(),\n",
        "            \"category\": fake.random_element(elements=(\"Electronics\", \"Clothing\", \"Food\", \"Books\")),\n",
        "            \"price\": round(random.uniform(10, 1000), 2)\n",
        "        }\n",
        "        products.append(product)\n",
        "    return products\n",
        "\n",
        "def generate_sales(n, num_customers, num_products):\n",
        "    sales = []\n",
        "    for i in range(n):\n",
        "        sale = {\n",
        "            \"sale_id\": i,\n",
        "            \"customer_id\": random.randint(0, num_customers - 1),\n",
        "            \"product_id\": random.randint(0, num_products - 1),\n",
        "            \"quantity\": random.randint(1, 10),\n",
        "            \"total_amount\": round(random.uniform(20, 2000), 2),\n",
        "            \"sale_date\": fake.date_between(start_date='-1y', end_date='today')\n",
        "        }\n",
        "        sales.append(sale)\n",
        "    return sales\n"
      ],
      "metadata": {
        "id": "PQkafpaEuNt6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data\n",
        "num_customers = 500\n",
        "num_products = 50\n",
        "num_sales = 10000\n",
        "\n",
        "customers_data = generate_customers(num_customers)\n",
        "products_data = generate_products(num_products)\n",
        "sales_data = generate_sales(num_sales, num_customers, num_products)\n",
        "\n",
        "# Define schemas\n",
        "customer_schema = StructType([\n",
        "    StructField(\"customer_id\", IntegerType(), True),\n",
        "    StructField(\"first_name\", StringType(), True),\n",
        "    StructField(\"last_name\", StringType(), True),\n",
        "    StructField(\"email\", StringType(), True),\n",
        "    StructField(\"is_active\", BooleanType(), True),\n",
        "    StructField(\"is_loyalty_member\", BooleanType(), True)\n",
        "])\n",
        "\n",
        "product_schema = StructType([\n",
        "    StructField(\"product_id\", IntegerType(), True),\n",
        "    StructField(\"product_name\", StringType(), True),\n",
        "    StructField(\"category\", StringType(), True),\n",
        "    StructField(\"price\", FloatType(), True)\n",
        "])\n",
        "\n",
        "sales_schema = StructType([\n",
        "    StructField(\"sale_id\", IntegerType(), True),\n",
        "    StructField(\"customer_id\", IntegerType(), True),\n",
        "    StructField(\"product_id\", IntegerType(), True),\n",
        "    StructField(\"quantity\", IntegerType(), True),\n",
        "    StructField(\"total_amount\", FloatType(), True),\n",
        "    StructField(\"sale_date\", DateType(), True)\n",
        "])\n",
        "\n",
        "# Create Spark DataFrames\n",
        "customers_df = spark.createDataFrame(customers_data, schema=customer_schema)\n",
        "products_df = spark.createDataFrame(products_data, schema=product_schema)\n",
        "sales_df = spark.createDataFrame(sales_data, schema=sales_schema)\n"
      ],
      "metadata": {
        "id": "owbn3ydrunAB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5SfoeEcva1S",
        "outputId": "18a29722-2507-4018-bba9-34528b14e72b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------+--------+------------+----------+\n",
            "|sale_id|customer_id|product_id|quantity|total_amount| sale_date|\n",
            "+-------+-----------+----------+--------+------------+----------+\n",
            "|      0|        450|        38|       9|     1285.13|2023-09-15|\n",
            "|      1|         17|        45|       4|     1953.44|2024-07-08|\n",
            "|      2|        104|        38|       4|     1185.28|2024-03-20|\n",
            "|      3|        481|         4|       8|      318.61|2024-02-18|\n",
            "|      4|         83|        35|       1|      238.84|2024-03-08|\n",
            "|      5|        478|        46|       6|      527.09|2023-12-25|\n",
            "|      6|        403|        27|       2|      893.08|2024-01-03|\n",
            "|      7|        198|        24|       5|      264.86|2024-05-24|\n",
            "|      8|         62|        22|       5|      565.63|2024-02-06|\n",
            "|      9|         20|        39|       3|      965.33|2023-10-13|\n",
            "|     10|        347|        20|       2|     1464.17|2023-09-23|\n",
            "|     11|        462|        10|      10|       515.0|2023-08-27|\n",
            "|     12|        230|        48|       7|     1352.59|2024-02-25|\n",
            "|     13|         72|        10|       9|     1598.21|2024-01-06|\n",
            "|     14|        296|        46|       3|      324.94|2024-01-09|\n",
            "|     15|        362|         2|       5|      581.13|2023-12-23|\n",
            "|     16|         43|        49|       6|      282.05|2024-04-04|\n",
            "|     17|        265|        44|       3|     1690.81|2023-08-13|\n",
            "|     18|        426|         7|      10|     1662.09|2024-06-10|\n",
            "|     19|        376|        37|       6|      1279.4|2024-02-16|\n",
            "+-------+-----------+----------+--------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How would you select the first_name and last_name columns from the customers_df DataFrame using the col() function?\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "names = customers_df.select(col(\"first_name\"), col('last_name'))\n",
        "names.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baMCn-88083w",
        "outputId": "27091235-2ec0-4cee-f8ae-55529800461e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+\n",
            "|first_name|last_name|\n",
            "+----------+---------+\n",
            "|    Martha|  Ramirez|\n",
            "|   Tiffany|   Harris|\n",
            "|   Tristan|   Benson|\n",
            "| Elizabeth|   Herman|\n",
            "|     Lance|     Wade|\n",
            "|   Rebecca|  Jackson|\n",
            "|      Dana|   Nguyen|\n",
            "|      Tara|  Watkins|\n",
            "|   Vanessa|   Garcia|\n",
            "|  Jonathan|    White|\n",
            "|    Thomas|  Collins|\n",
            "|   Spencer| Thompson|\n",
            "|    Daniel|Hernandez|\n",
            "|    Deanna| Johnston|\n",
            "|    Isabel|    Clark|\n",
            "|    Dennis|    Casey|\n",
            "|   Michael|     Wood|\n",
            "|   Michael|  Sanchez|\n",
            "|     Barry|    Perez|\n",
            "|      Paul|     Cole|\n",
            "+----------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the expr() function, how would you create a new column in the sales_df DataFrame that calculates the total price as quantity * total_amount?\n",
        "\n",
        "sales_df = sales_df.withColumn('total_price', expr('quantity * total_amount'))\n",
        "sales_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpA8GjWD2iMp",
        "outputId": "c8ae38d4-2e0c-43a0-8967-662e2a47adeb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------+--------+------------+----------+-----------+\n",
            "|sale_id|customer_id|product_id|quantity|total_amount| sale_date|total_price|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+\n",
            "|      0|        450|        38|       9|     1285.13|2023-09-15|   11566.17|\n",
            "|      1|         17|        45|       4|     1953.44|2024-07-08|    7813.76|\n",
            "|      2|        104|        38|       4|     1185.28|2024-03-20|    4741.12|\n",
            "|      3|        481|         4|       8|      318.61|2024-02-18|    2548.88|\n",
            "|      4|         83|        35|       1|      238.84|2024-03-08|     238.84|\n",
            "|      5|        478|        46|       6|      527.09|2023-12-25|    3162.54|\n",
            "|      6|        403|        27|       2|      893.08|2024-01-03|    1786.16|\n",
            "|      7|        198|        24|       5|      264.86|2024-05-24|  1324.2999|\n",
            "|      8|         62|        22|       5|      565.63|2024-02-06|    2828.15|\n",
            "|      9|         20|        39|       3|      965.33|2023-10-13|    2895.99|\n",
            "|     10|        347|        20|       2|     1464.17|2023-09-23|    2928.34|\n",
            "|     11|        462|        10|      10|       515.0|2023-08-27|     5150.0|\n",
            "|     12|        230|        48|       7|     1352.59|2024-02-25|    9468.13|\n",
            "|     13|         72|        10|       9|     1598.21|2024-01-06|   14383.89|\n",
            "|     14|        296|        46|       3|      324.94|2024-01-09|     974.82|\n",
            "|     15|        362|         2|       5|      581.13|2023-12-23|    2905.65|\n",
            "|     16|         43|        49|       6|      282.05|2024-04-04|  1692.2999|\n",
            "|     17|        265|        44|       3|     1690.81|2023-08-13|    5072.43|\n",
            "|     18|        426|         7|      10|     1662.09|2024-06-10|    16620.9|\n",
            "|     19|        376|        37|       6|      1279.4|2024-02-16|  7676.4004|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Using the when() and otherwise() functions, how would you create a new column in the products_df DataFrame that labels products as \"Expensive\" if the price is greater than $500, and \"Affordable\" otherwise?\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "products_df = products_df.withColumn('product_tag', when(col('price')>500, 'Expensive').otherwise('Affordable'))\n",
        "products_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcMQDSVE0813",
        "outputId": "28df1d72-be30-4b20-995b-b890741820b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+-----------+------+-----------+\n",
            "|product_id|product_name|   category| price|product_tag|\n",
            "+----------+------------+-----------+------+-----------+\n",
            "|         0|       under|   Clothing|391.76| Affordable|\n",
            "|         1|          at|       Food|920.41|  Expensive|\n",
            "|         2|    language|   Clothing|852.81|  Expensive|\n",
            "|         3|       party|       Food|728.56|  Expensive|\n",
            "|         4|         few|Electronics|463.27| Affordable|\n",
            "|         5|       trial|Electronics|924.68|  Expensive|\n",
            "|         6|     between|Electronics| 526.8|  Expensive|\n",
            "|         7|    daughter|       Food|434.68| Affordable|\n",
            "|         8|      choose|      Books|769.56|  Expensive|\n",
            "|         9|         tax|      Books|277.17| Affordable|\n",
            "|        10|         her|   Clothing|495.27| Affordable|\n",
            "|        11|        side|       Food|807.75|  Expensive|\n",
            "|        12|     history|      Books|724.07|  Expensive|\n",
            "|        13|       month|      Books|116.21| Affordable|\n",
            "|        14|          if|       Food|489.56| Affordable|\n",
            "|        15|       short|      Books|338.52| Affordable|\n",
            "|        16|      common|      Books|303.64| Affordable|\n",
            "|        17|         hot|      Books|830.06|  Expensive|\n",
            "|        18|      common|   Clothing|942.72|  Expensive|\n",
            "|        19|         why|       Food| 84.68| Affordable|\n",
            "+----------+------------+-----------+------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the average total_amount for all sales in the sales_df DataFrame?\n",
        "from pyspark.sql.functions import avg, count\n",
        "\n",
        "sales_df.groupBy(col('product_id')).agg(avg(col('total_amount')).alias('avg_sales'), count(col('total_amount'))).orderBy(col('product_id')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDSlhRKs08zl",
        "outputId": "403168a1-edf5-49d5-902d-bf3b63ab259b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+-------------------+\n",
            "|product_id|         avg_sales|count(total_amount)|\n",
            "+----------+------------------+-------------------+\n",
            "|         0|1046.4491488075257|                200|\n",
            "|         1|1023.1973235679395|                198|\n",
            "|         2|1031.7267689798393|                204|\n",
            "|         3|1014.8981739372335|                186|\n",
            "|         4|1016.7443236346221|                199|\n",
            "|         5| 1081.031818132944|                193|\n",
            "|         6| 961.0983561235873|                201|\n",
            "|         7|1074.5456086819765|                189|\n",
            "|         8|1040.1062793639546|                207|\n",
            "|         9|1013.7342090228997|                202|\n",
            "|        10|1006.7672905699114|                214|\n",
            "|        11| 965.6692328161123|                196|\n",
            "|        12|1104.1070320582626|                202|\n",
            "|        13| 988.2838834357385|                193|\n",
            "|        14|1052.7073091569837|                182|\n",
            "|        15| 1004.337927426693|                207|\n",
            "|        16|1012.0410111408967|                208|\n",
            "|        17|1077.1398408274172|                189|\n",
            "|        18| 1039.809005323039|                221|\n",
            "|        19|1007.5834627630991|                179|\n",
            "+----------+------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how would you determine the number of active customers in the customers_df DataFrame?\n",
        "customers_df.groupBy(col('is_active')).agg(count(col('customer_id'))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MybCnuBM08w_",
        "outputId": "0c2176b0-0bb8-4a86-8d17-bf8549c6e4d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+\n",
            "|is_active|count(customer_id)|\n",
            "+---------+------------------+\n",
            "|     true|               245|\n",
            "|    false|               255|\n",
            "+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new column in the customers_df DataFrame that combines first_name and last_name into a single full_name column?\n",
        "\n",
        "from pyspark.sql.functions import concat, lit\n",
        "customers_df.withColumn('full_name', concat(col('first_name'), lit(' '), col('last_name'))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RTxt_8X08r7",
        "outputId": "3337c1aa-2d5d-49c9-83ca-47389bbc8e9b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+---------+--------------------+---------+-----------------+----------------+\n",
            "|customer_id|first_name|last_name|               email|is_active|is_loyalty_member|       full_name|\n",
            "+-----------+----------+---------+--------------------+---------+-----------------+----------------+\n",
            "|          0|    Martha|  Ramirez| bryan66@example.com|     true|             true|  Martha Ramirez|\n",
            "|          1|   Tiffany|   Harris|annachan@example.com|     true|             true|  Tiffany Harris|\n",
            "|          2|   Tristan|   Benson|travis09@example.com|     true|            false|  Tristan Benson|\n",
            "|          3| Elizabeth|   Herman|nathanielanderson...|     true|            false|Elizabeth Herman|\n",
            "|          4|     Lance|     Wade|rjohnson@example.org|     true|             true|      Lance Wade|\n",
            "|          5|   Rebecca|  Jackson|brocknatasha@exam...|    false|             true| Rebecca Jackson|\n",
            "|          6|      Dana|   Nguyen|hholloway@example...|     true|            false|     Dana Nguyen|\n",
            "|          7|      Tara|  Watkins|alyssarichardson@...|    false|            false|    Tara Watkins|\n",
            "|          8|   Vanessa|   Garcia|tdaniels@example.org|    false|             true|  Vanessa Garcia|\n",
            "|          9|  Jonathan|    White|jocelyn55@example...|    false|            false|  Jonathan White|\n",
            "|         10|    Thomas|  Collins|   vward@example.com|     true|             true|  Thomas Collins|\n",
            "|         11|   Spencer| Thompson| xstrong@example.net|     true|            false|Spencer Thompson|\n",
            "|         12|    Daniel|Hernandez|annacarter@exampl...|     true|            false|Daniel Hernandez|\n",
            "|         13|    Deanna| Johnston|jennifer14@exampl...|     true|            false| Deanna Johnston|\n",
            "|         14|    Isabel|    Clark|kristinahansen@ex...|    false|            false|    Isabel Clark|\n",
            "|         15|    Dennis|    Casey|stantonandrea@exa...|     true|            false|    Dennis Casey|\n",
            "|         16|   Michael|     Wood|amanda55@example.net|     true|             true|    Michael Wood|\n",
            "|         17|   Michael|  Sanchez|   rhill@example.org|    false|             true| Michael Sanchez|\n",
            "|         18|     Barry|    Perez|greenjames@exampl...|    false|             true|     Barry Perez|\n",
            "|         19|      Paul|     Cole|  ismith@example.org|    false|             true|       Paul Cole|\n",
            "+-----------+----------+---------+--------------------+---------+-----------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How would you extract the first three characters from the product_name column in the products_df DataFrame\n",
        "from pyspark.sql.functions import substring, upper\n",
        "products_df.withColumn('name_code', upper(substring(col('product_name'), 1, 3))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf2Eo79c5sSM",
        "outputId": "273df12c-b80f-4b66-e083-0545834f2a41"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+-----------+------+-----------+---------+\n",
            "|product_id|product_name|   category| price|product_tag|name_code|\n",
            "+----------+------------+-----------+------+-----------+---------+\n",
            "|         0|       under|   Clothing|391.76| Affordable|      UND|\n",
            "|         1|          at|       Food|920.41|  Expensive|       AT|\n",
            "|         2|    language|   Clothing|852.81|  Expensive|      LAN|\n",
            "|         3|       party|       Food|728.56|  Expensive|      PAR|\n",
            "|         4|         few|Electronics|463.27| Affordable|      FEW|\n",
            "|         5|       trial|Electronics|924.68|  Expensive|      TRI|\n",
            "|         6|     between|Electronics| 526.8|  Expensive|      BET|\n",
            "|         7|    daughter|       Food|434.68| Affordable|      DAU|\n",
            "|         8|      choose|      Books|769.56|  Expensive|      CHO|\n",
            "|         9|         tax|      Books|277.17| Affordable|      TAX|\n",
            "|        10|         her|   Clothing|495.27| Affordable|      HER|\n",
            "|        11|        side|       Food|807.75|  Expensive|      SID|\n",
            "|        12|     history|      Books|724.07|  Expensive|      HIS|\n",
            "|        13|       month|      Books|116.21| Affordable|      MON|\n",
            "|        14|          if|       Food|489.56| Affordable|       IF|\n",
            "|        15|       short|      Books|338.52| Affordable|      SHO|\n",
            "|        16|      common|      Books|303.64| Affordable|      COM|\n",
            "|        17|         hot|      Books|830.06|  Expensive|      HOT|\n",
            "|        18|      common|   Clothing|942.72|  Expensive|      COM|\n",
            "|        19|         why|       Food| 84.68| Affordable|      WHY|\n",
            "+----------+------------+-----------+------+-----------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the sale_date column in the sales_df DataFrame to a format like \"MM-dd-yyyy\"?\n",
        "from pyspark.sql.functions import date_format\n",
        "\n",
        "sales_df.withColumn('sale_date_reformat', date_format(col('sale_date'), \"MM-dd-yyyy\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JITBdxIY5sQO",
        "outputId": "335a5c83-97cc-4f1c-dcc4-373375b38078"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------+--------+------------+----------+-----------+------------------+\n",
            "|sale_id|customer_id|product_id|quantity|total_amount| sale_date|total_price|sale_date_reformat|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+------------------+\n",
            "|      0|        450|        38|       9|     1285.13|2023-09-15|   11566.17|        09-15-2023|\n",
            "|      1|         17|        45|       4|     1953.44|2024-07-08|    7813.76|        07-08-2024|\n",
            "|      2|        104|        38|       4|     1185.28|2024-03-20|    4741.12|        03-20-2024|\n",
            "|      3|        481|         4|       8|      318.61|2024-02-18|    2548.88|        02-18-2024|\n",
            "|      4|         83|        35|       1|      238.84|2024-03-08|     238.84|        03-08-2024|\n",
            "|      5|        478|        46|       6|      527.09|2023-12-25|    3162.54|        12-25-2023|\n",
            "|      6|        403|        27|       2|      893.08|2024-01-03|    1786.16|        01-03-2024|\n",
            "|      7|        198|        24|       5|      264.86|2024-05-24|  1324.2999|        05-24-2024|\n",
            "|      8|         62|        22|       5|      565.63|2024-02-06|    2828.15|        02-06-2024|\n",
            "|      9|         20|        39|       3|      965.33|2023-10-13|    2895.99|        10-13-2023|\n",
            "|     10|        347|        20|       2|     1464.17|2023-09-23|    2928.34|        09-23-2023|\n",
            "|     11|        462|        10|      10|       515.0|2023-08-27|     5150.0|        08-27-2023|\n",
            "|     12|        230|        48|       7|     1352.59|2024-02-25|    9468.13|        02-25-2024|\n",
            "|     13|         72|        10|       9|     1598.21|2024-01-06|   14383.89|        01-06-2024|\n",
            "|     14|        296|        46|       3|      324.94|2024-01-09|     974.82|        01-09-2024|\n",
            "|     15|        362|         2|       5|      581.13|2023-12-23|    2905.65|        12-23-2023|\n",
            "|     16|         43|        49|       6|      282.05|2024-04-04|  1692.2999|        04-04-2024|\n",
            "|     17|        265|        44|       3|     1690.81|2023-08-13|    5072.43|        08-13-2023|\n",
            "|     18|        426|         7|      10|     1662.09|2024-06-10|    16620.9|        06-10-2024|\n",
            "|     19|        376|        37|       6|      1279.4|2024-02-16|  7676.4004|        02-16-2024|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how would you calculate a new column in the sales_df DataFrame that adds 6 months to each sale_date?\n",
        "from pyspark.sql.functions import add_months\n",
        "\n",
        "sales_df.withColumn('six_mth_from_sale_date', add_months(col('sale_date'), 6)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bpuS_ZF5sN9",
        "outputId": "cf40d77e-5701-4793-de34-ab6496a81f8f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------+--------+------------+----------+-----------+----------------------+\n",
            "|sale_id|customer_id|product_id|quantity|total_amount| sale_date|total_price|six_mth_from_sale_date|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+----------------------+\n",
            "|      0|        450|        38|       9|     1285.13|2023-09-15|   11566.17|            2024-03-15|\n",
            "|      1|         17|        45|       4|     1953.44|2024-07-08|    7813.76|            2025-01-08|\n",
            "|      2|        104|        38|       4|     1185.28|2024-03-20|    4741.12|            2024-09-20|\n",
            "|      3|        481|         4|       8|      318.61|2024-02-18|    2548.88|            2024-08-18|\n",
            "|      4|         83|        35|       1|      238.84|2024-03-08|     238.84|            2024-09-08|\n",
            "|      5|        478|        46|       6|      527.09|2023-12-25|    3162.54|            2024-06-25|\n",
            "|      6|        403|        27|       2|      893.08|2024-01-03|    1786.16|            2024-07-03|\n",
            "|      7|        198|        24|       5|      264.86|2024-05-24|  1324.2999|            2024-11-24|\n",
            "|      8|         62|        22|       5|      565.63|2024-02-06|    2828.15|            2024-08-06|\n",
            "|      9|         20|        39|       3|      965.33|2023-10-13|    2895.99|            2024-04-13|\n",
            "|     10|        347|        20|       2|     1464.17|2023-09-23|    2928.34|            2024-03-23|\n",
            "|     11|        462|        10|      10|       515.0|2023-08-27|     5150.0|            2024-02-27|\n",
            "|     12|        230|        48|       7|     1352.59|2024-02-25|    9468.13|            2024-08-25|\n",
            "|     13|         72|        10|       9|     1598.21|2024-01-06|   14383.89|            2024-07-06|\n",
            "|     14|        296|        46|       3|      324.94|2024-01-09|     974.82|            2024-07-09|\n",
            "|     15|        362|         2|       5|      581.13|2023-12-23|    2905.65|            2024-06-23|\n",
            "|     16|         43|        49|       6|      282.05|2024-04-04|  1692.2999|            2024-10-04|\n",
            "|     17|        265|        44|       3|     1690.81|2023-08-13|    5072.43|            2024-02-13|\n",
            "|     18|        426|         7|      10|     1662.09|2024-06-10|    16620.9|            2024-12-10|\n",
            "|     19|        376|        37|       6|      1279.4|2024-02-16|  7676.4004|            2024-08-16|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How would you create a new column in the sales_df DataFrame that calculates the square root of the total_amount for each sale?\n",
        "from pyspark.sql.functions import sqrt, round\n",
        "\n",
        "sales_df.withColumn('sqrt_total_amount', round(sqrt(col('total_amount')), 2)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65c9ECrk5sLn",
        "outputId": "4134f6be-494b-4115-d52d-486a2666ed51"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------+--------+------------+----------+-----------+-----------------+\n",
            "|sale_id|customer_id|product_id|quantity|total_amount| sale_date|total_price|sqrt_total_amount|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+-----------------+\n",
            "|      0|        450|        38|       9|     1285.13|2023-09-15|   11566.17|            35.85|\n",
            "|      1|         17|        45|       4|     1953.44|2024-07-08|    7813.76|             44.2|\n",
            "|      2|        104|        38|       4|     1185.28|2024-03-20|    4741.12|            34.43|\n",
            "|      3|        481|         4|       8|      318.61|2024-02-18|    2548.88|            17.85|\n",
            "|      4|         83|        35|       1|      238.84|2024-03-08|     238.84|            15.45|\n",
            "|      5|        478|        46|       6|      527.09|2023-12-25|    3162.54|            22.96|\n",
            "|      6|        403|        27|       2|      893.08|2024-01-03|    1786.16|            29.88|\n",
            "|      7|        198|        24|       5|      264.86|2024-05-24|  1324.2999|            16.27|\n",
            "|      8|         62|        22|       5|      565.63|2024-02-06|    2828.15|            23.78|\n",
            "|      9|         20|        39|       3|      965.33|2023-10-13|    2895.99|            31.07|\n",
            "|     10|        347|        20|       2|     1464.17|2023-09-23|    2928.34|            38.26|\n",
            "|     11|        462|        10|      10|       515.0|2023-08-27|     5150.0|            22.69|\n",
            "|     12|        230|        48|       7|     1352.59|2024-02-25|    9468.13|            36.78|\n",
            "|     13|         72|        10|       9|     1598.21|2024-01-06|   14383.89|            39.98|\n",
            "|     14|        296|        46|       3|      324.94|2024-01-09|     974.82|            18.03|\n",
            "|     15|        362|         2|       5|      581.13|2023-12-23|    2905.65|            24.11|\n",
            "|     16|         43|        49|       6|      282.05|2024-04-04|  1692.2999|            16.79|\n",
            "|     17|        265|        44|       3|     1690.81|2023-08-13|    5072.43|            41.12|\n",
            "|     18|        426|         7|      10|     1662.09|2024-06-10|    16620.9|            40.77|\n",
            "|     19|        376|        37|       6|      1279.4|2024-02-16|  7676.4004|            35.77|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the sales_df DataFrame, how would you compute a new column that represents the absolute difference between total_amount and a fixed value, say $100?\n",
        "from pyspark.sql.functions import abs\n",
        "\n",
        "sales_df.withColumn('total_amount_shift', abs(100 - col('total_amount'))).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12TL4uVR-mBV",
        "outputId": "dc1dc07e-0bca-48b1-e801-825d320f54d3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------+--------+------------+----------+-----------+------------------+\n",
            "|sale_id|customer_id|product_id|quantity|total_amount| sale_date|total_price|total_amount_shift|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+------------------+\n",
            "|      0|        450|        38|       9|     1285.13|2023-09-15|   11566.17|           1185.13|\n",
            "|      1|         17|        45|       4|     1953.44|2024-07-08|    7813.76|           1853.44|\n",
            "|      2|        104|        38|       4|     1185.28|2024-03-20|    4741.12|           1085.28|\n",
            "|      3|        481|         4|       8|      318.61|2024-02-18|    2548.88|         218.60999|\n",
            "|      4|         83|        35|       1|      238.84|2024-03-08|     238.84|            138.84|\n",
            "|      5|        478|        46|       6|      527.09|2023-12-25|    3162.54|         427.09003|\n",
            "|      6|        403|        27|       2|      893.08|2024-01-03|    1786.16|            793.08|\n",
            "|      7|        198|        24|       5|      264.86|2024-05-24|  1324.2999|         164.85999|\n",
            "|      8|         62|        22|       5|      565.63|2024-02-06|    2828.15|            465.63|\n",
            "|      9|         20|        39|       3|      965.33|2023-10-13|    2895.99|            865.33|\n",
            "|     10|        347|        20|       2|     1464.17|2023-09-23|    2928.34|           1364.17|\n",
            "|     11|        462|        10|      10|       515.0|2023-08-27|     5150.0|             415.0|\n",
            "|     12|        230|        48|       7|     1352.59|2024-02-25|    9468.13|           1252.59|\n",
            "|     13|         72|        10|       9|     1598.21|2024-01-06|   14383.89|           1498.21|\n",
            "|     14|        296|        46|       3|      324.94|2024-01-09|     974.82|            224.94|\n",
            "|     15|        362|         2|       5|      581.13|2023-12-23|    2905.65|            481.13|\n",
            "|     16|         43|        49|       6|      282.05|2024-04-04|  1692.2999|         182.04999|\n",
            "|     17|        265|        44|       3|     1690.81|2023-08-13|    5072.43|           1590.81|\n",
            "|     18|        426|         7|      10|     1662.09|2024-06-10|    16620.9|           1562.09|\n",
            "|     19|        376|        37|       6|      1279.4|2024-02-16|  7676.4004|            1179.4|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the customers_df DataFrame, how would you check which rows have a null value in the email column?\n",
        "customers_df.filter(col('email').isNull()).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsBQOSpK-l_U",
        "outputId": "37d881a2-6783-4286-c2ab-745171ff89c4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+---------+-----+---------+-----------------+\n",
            "|customer_id|first_name|last_name|email|is_active|is_loyalty_member|\n",
            "+-----------+----------+---------+-----+---------+-----------------+\n",
            "+-----------+----------+---------+-----+---------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How would you filter out all rows from the sales_df DataFrame where the total_amount column contains NaN values?\n",
        "sales_df.filter(col('total_amount').isNull()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slZgROIB-l9H",
        "outputId": "0999764f-8501-4348-804f-b16690113e82"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------+--------+------------+---------+-----------+\n",
            "|sale_id|customer_id|product_id|quantity|total_amount|sale_date|total_price|\n",
            "+-------+-----------+----------+--------+------------+---------+-----------+\n",
            "+-------+-----------+----------+--------+------------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How would you convert the price column in the products_df DataFrame from a float to an integer?\n",
        "products_df.withColumn('price', col('price').cast('integer')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRW4_tUy-l6p",
        "outputId": "8dbcd9ee-6cca-4cf7-d9ce-c1022b7be95d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+-----------+-----+-----------+\n",
            "|product_id|product_name|   category|price|product_tag|\n",
            "+----------+------------+-----------+-----+-----------+\n",
            "|         0|       under|   Clothing|  391| Affordable|\n",
            "|         1|          at|       Food|  920|  Expensive|\n",
            "|         2|    language|   Clothing|  852|  Expensive|\n",
            "|         3|       party|       Food|  728|  Expensive|\n",
            "|         4|         few|Electronics|  463| Affordable|\n",
            "|         5|       trial|Electronics|  924|  Expensive|\n",
            "|         6|     between|Electronics|  526|  Expensive|\n",
            "|         7|    daughter|       Food|  434| Affordable|\n",
            "|         8|      choose|      Books|  769|  Expensive|\n",
            "|         9|         tax|      Books|  277| Affordable|\n",
            "|        10|         her|   Clothing|  495| Affordable|\n",
            "|        11|        side|       Food|  807|  Expensive|\n",
            "|        12|     history|      Books|  724|  Expensive|\n",
            "|        13|       month|      Books|  116| Affordable|\n",
            "|        14|          if|       Food|  489| Affordable|\n",
            "|        15|       short|      Books|  338| Affordable|\n",
            "|        16|      common|      Books|  303| Affordable|\n",
            "|        17|         hot|      Books|  830|  Expensive|\n",
            "|        18|      common|   Clothing|  942|  Expensive|\n",
            "|        19|         why|       Food|   84| Affordable|\n",
            "+----------+------------+-----------+-----+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the sales_df DataFrame, how would you change the sale_date column from a date type to a string type?\n",
        "sales_df.withColumn('sale_date', col('sale_date').cast('string')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eScqj7hAJlF",
        "outputId": "7b090481-a05e-446a-9a79-7a81ebfbe237"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------+--------+------------+----------+-----------+\n",
            "|sale_id|customer_id|product_id|quantity|total_amount| sale_date|total_price|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+\n",
            "|      0|        450|        38|       9|     1285.13|2023-09-15|   11566.17|\n",
            "|      1|         17|        45|       4|     1953.44|2024-07-08|    7813.76|\n",
            "|      2|        104|        38|       4|     1185.28|2024-03-20|    4741.12|\n",
            "|      3|        481|         4|       8|      318.61|2024-02-18|    2548.88|\n",
            "|      4|         83|        35|       1|      238.84|2024-03-08|     238.84|\n",
            "|      5|        478|        46|       6|      527.09|2023-12-25|    3162.54|\n",
            "|      6|        403|        27|       2|      893.08|2024-01-03|    1786.16|\n",
            "|      7|        198|        24|       5|      264.86|2024-05-24|  1324.2999|\n",
            "|      8|         62|        22|       5|      565.63|2024-02-06|    2828.15|\n",
            "|      9|         20|        39|       3|      965.33|2023-10-13|    2895.99|\n",
            "|     10|        347|        20|       2|     1464.17|2023-09-23|    2928.34|\n",
            "|     11|        462|        10|      10|       515.0|2023-08-27|     5150.0|\n",
            "|     12|        230|        48|       7|     1352.59|2024-02-25|    9468.13|\n",
            "|     13|         72|        10|       9|     1598.21|2024-01-06|   14383.89|\n",
            "|     14|        296|        46|       3|      324.94|2024-01-09|     974.82|\n",
            "|     15|        362|         2|       5|      581.13|2023-12-23|    2905.65|\n",
            "|     16|         43|        49|       6|      282.05|2024-04-04|  1692.2999|\n",
            "|     17|        265|        44|       3|     1690.81|2023-08-13|    5072.43|\n",
            "|     18|        426|         7|      10|     1662.09|2024-06-10|    16620.9|\n",
            "|     19|        376|        37|       6|      1279.4|2024-02-16|  7676.4004|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How would you create a new column in the products_df DataFrame that stores the product_name and category as an array?\n",
        "from pyspark.sql.functions import array, explode\n",
        "\n",
        "products_df.withColumn('product_info', array(col('product_name'), col('category'))).show()\n",
        "\n",
        "# how would i explode this and show all columns?\n",
        "products_df.withColumn('product_info', array(col('product_name'), col('category'))).select('*', explode(col('product_info'))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9sahWa5AJjJ",
        "outputId": "7d9b3e63-22bf-49c7-dc62-4d77e48a8938"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+-----------+------+-----------+--------------------+\n",
            "|product_id|product_name|   category| price|product_tag|        product_info|\n",
            "+----------+------------+-----------+------+-----------+--------------------+\n",
            "|         0|       under|   Clothing|391.76| Affordable|   [under, Clothing]|\n",
            "|         1|          at|       Food|920.41|  Expensive|          [at, Food]|\n",
            "|         2|    language|   Clothing|852.81|  Expensive|[language, Clothing]|\n",
            "|         3|       party|       Food|728.56|  Expensive|       [party, Food]|\n",
            "|         4|         few|Electronics|463.27| Affordable|  [few, Electronics]|\n",
            "|         5|       trial|Electronics|924.68|  Expensive|[trial, Electronics]|\n",
            "|         6|     between|Electronics| 526.8|  Expensive|[between, Electro...|\n",
            "|         7|    daughter|       Food|434.68| Affordable|    [daughter, Food]|\n",
            "|         8|      choose|      Books|769.56|  Expensive|     [choose, Books]|\n",
            "|         9|         tax|      Books|277.17| Affordable|        [tax, Books]|\n",
            "|        10|         her|   Clothing|495.27| Affordable|     [her, Clothing]|\n",
            "|        11|        side|       Food|807.75|  Expensive|        [side, Food]|\n",
            "|        12|     history|      Books|724.07|  Expensive|    [history, Books]|\n",
            "|        13|       month|      Books|116.21| Affordable|      [month, Books]|\n",
            "|        14|          if|       Food|489.56| Affordable|          [if, Food]|\n",
            "|        15|       short|      Books|338.52| Affordable|      [short, Books]|\n",
            "|        16|      common|      Books|303.64| Affordable|     [common, Books]|\n",
            "|        17|         hot|      Books|830.06|  Expensive|        [hot, Books]|\n",
            "|        18|      common|   Clothing|942.72|  Expensive|  [common, Clothing]|\n",
            "|        19|         why|       Food| 84.68| Affordable|         [why, Food]|\n",
            "+----------+------------+-----------+------+-----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----------+------------+-----------+------+-----------+--------------------+-----------+\n",
            "|product_id|product_name|   category| price|product_tag|        product_info|        col|\n",
            "+----------+------------+-----------+------+-----------+--------------------+-----------+\n",
            "|         0|       under|   Clothing|391.76| Affordable|   [under, Clothing]|      under|\n",
            "|         0|       under|   Clothing|391.76| Affordable|   [under, Clothing]|   Clothing|\n",
            "|         1|          at|       Food|920.41|  Expensive|          [at, Food]|         at|\n",
            "|         1|          at|       Food|920.41|  Expensive|          [at, Food]|       Food|\n",
            "|         2|    language|   Clothing|852.81|  Expensive|[language, Clothing]|   language|\n",
            "|         2|    language|   Clothing|852.81|  Expensive|[language, Clothing]|   Clothing|\n",
            "|         3|       party|       Food|728.56|  Expensive|       [party, Food]|      party|\n",
            "|         3|       party|       Food|728.56|  Expensive|       [party, Food]|       Food|\n",
            "|         4|         few|Electronics|463.27| Affordable|  [few, Electronics]|        few|\n",
            "|         4|         few|Electronics|463.27| Affordable|  [few, Electronics]|Electronics|\n",
            "|         5|       trial|Electronics|924.68|  Expensive|[trial, Electronics]|      trial|\n",
            "|         5|       trial|Electronics|924.68|  Expensive|[trial, Electronics]|Electronics|\n",
            "|         6|     between|Electronics| 526.8|  Expensive|[between, Electro...|    between|\n",
            "|         6|     between|Electronics| 526.8|  Expensive|[between, Electro...|Electronics|\n",
            "|         7|    daughter|       Food|434.68| Affordable|    [daughter, Food]|   daughter|\n",
            "|         7|    daughter|       Food|434.68| Affordable|    [daughter, Food]|       Food|\n",
            "|         8|      choose|      Books|769.56|  Expensive|     [choose, Books]|     choose|\n",
            "|         8|      choose|      Books|769.56|  Expensive|     [choose, Books]|      Books|\n",
            "|         9|         tax|      Books|277.17| Affordable|        [tax, Books]|        tax|\n",
            "|         9|         tax|      Books|277.17| Affordable|        [tax, Books]|      Books|\n",
            "+----------+------------+-----------+------+-----------+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the sales_df DataFrame, how would you construct a map column where the keys are product_id and the values are quantity?\n",
        "from pyspark.sql.functions import create_map\n",
        "\n",
        "sales_df.withColumn('product_quantity', create_map(col('product_id'), col('quantity'))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0DNddogAJgd",
        "outputId": "ef6947b8-4c4d-4362-a8fc-7c1d016c89dd"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------+--------+------------+----------+-----------+----------------+\n",
            "|sale_id|customer_id|product_id|quantity|total_amount| sale_date|total_price|product_quantity|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+----------------+\n",
            "|      0|        450|        38|       9|     1285.13|2023-09-15|   11566.17|       {38 -> 9}|\n",
            "|      1|         17|        45|       4|     1953.44|2024-07-08|    7813.76|       {45 -> 4}|\n",
            "|      2|        104|        38|       4|     1185.28|2024-03-20|    4741.12|       {38 -> 4}|\n",
            "|      3|        481|         4|       8|      318.61|2024-02-18|    2548.88|        {4 -> 8}|\n",
            "|      4|         83|        35|       1|      238.84|2024-03-08|     238.84|       {35 -> 1}|\n",
            "|      5|        478|        46|       6|      527.09|2023-12-25|    3162.54|       {46 -> 6}|\n",
            "|      6|        403|        27|       2|      893.08|2024-01-03|    1786.16|       {27 -> 2}|\n",
            "|      7|        198|        24|       5|      264.86|2024-05-24|  1324.2999|       {24 -> 5}|\n",
            "|      8|         62|        22|       5|      565.63|2024-02-06|    2828.15|       {22 -> 5}|\n",
            "|      9|         20|        39|       3|      965.33|2023-10-13|    2895.99|       {39 -> 3}|\n",
            "|     10|        347|        20|       2|     1464.17|2023-09-23|    2928.34|       {20 -> 2}|\n",
            "|     11|        462|        10|      10|       515.0|2023-08-27|     5150.0|      {10 -> 10}|\n",
            "|     12|        230|        48|       7|     1352.59|2024-02-25|    9468.13|       {48 -> 7}|\n",
            "|     13|         72|        10|       9|     1598.21|2024-01-06|   14383.89|       {10 -> 9}|\n",
            "|     14|        296|        46|       3|      324.94|2024-01-09|     974.82|       {46 -> 3}|\n",
            "|     15|        362|         2|       5|      581.13|2023-12-23|    2905.65|        {2 -> 5}|\n",
            "|     16|         43|        49|       6|      282.05|2024-04-04|  1692.2999|       {49 -> 6}|\n",
            "|     17|        265|        44|       3|     1690.81|2023-08-13|    5072.43|       {44 -> 3}|\n",
            "|     18|        426|         7|      10|     1662.09|2024-06-10|    16620.9|       {7 -> 10}|\n",
            "|     19|        376|        37|       6|      1279.4|2024-02-16|  7676.4004|       {37 -> 6}|\n",
            "+-------+-----------+----------+--------+------------+----------+-----------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis questions"
      ],
      "metadata": {
        "id": "oVjHKcbcCTQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How would you find the top 5 customers who have spent the most money on products in the \"Electronics\" category? i need only top 5 results\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "# Join the DataFrames on the product_id column\n",
        "# Filter for \"Electronics\" category\n",
        "# Select the required columns\n",
        "# Order by total_price in descending order\n",
        "# Show the top 5 customers\n",
        "\n",
        "sales_df.join(products_df, products_df.product_id == sales_df.product_id, how='left').where(col('category') == 'Electronics').select('customer_id', 'total_price').orderBy(desc(col('total_price'))).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrVqOD7yDwL7",
        "outputId": "e5a34521-f45d-4e6c-d007-1f476f0fee86"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|customer_id|total_price|\n",
            "+-----------+-----------+\n",
            "|        191|    19923.7|\n",
            "|        308|    19676.3|\n",
            "|        368|    19484.1|\n",
            "|        345|    19382.7|\n",
            "|        415|    19278.9|\n",
            "+-----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}